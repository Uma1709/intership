{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqH68piYAPUe9vd+bvlOGo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uma1709/intership/blob/main/week5(deep_learning46%2C47%2C48).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQBCKYdNDLTr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EVXrbRRODhUO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DCGAN(DCGAN stands for \"Deep Convolutional Generative Adversarial Network)"
      ],
      "metadata": {
        "id": "N-04gps7Dha-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "from PIL import Image\n",
        "from IPython import display\n",
        "import tensorflow.keras as kr\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import imageio\n",
        "import os"
      ],
      "metadata": {
        "id": "5qFIhbKNDjFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 128\n",
        "LATENT_DIM = 100\n",
        "SAMPLE_INTERVAL = 200\n",
        "EPOCHS = 10000"
      ],
      "metadata": {
        "id": "Qq7PiNsNDpyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_gif(gif_name='mnist_gan.gif', pattern='image*.png'):\n",
        "    with imageio.get_writer(gif_name, mode='I') as writer:\n",
        "        filenames = glob(pattern)\n",
        "        filenames = sorted(filenames)\n",
        "        last = -1\n",
        "        for i,filename in enumerate(filenames):\n",
        "            frame = 2*(i**0.5)\n",
        "            if round(frame) > round(last):\n",
        "                last = frame\n",
        "            else:\n",
        "                continue\n",
        "            image = imageio.imread(filename)\n",
        "            writer.append_data(image)\n",
        "\n",
        "        image = imageio.imread(filename)\n",
        "        writer.append_data(image)\n",
        "\n",
        "    # this is a hack to display the gif inside the notebook\n",
        "    os.system('cp {} {}.png'.format(gif_name, gif_name))"
      ],
      "metadata": {
        "id": "-E2535u3Dspc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_images(generator, epoch, save=True, name='mnist'):\n",
        "    \"\"\" Sample images from generator, plot them and save as png\"\"\"\n",
        "\n",
        "    noise = np.random.normal(size=(5 * 5, LATENT_DIM))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5     # Rescale images 0-1\n",
        "\n",
        "    fig, axs = plt.subplots(5, 5)\n",
        "    c = 0\n",
        "    for i in range(5):\n",
        "        for j in range(5):\n",
        "            axs[i,j].imshow(gen_imgs[c, :,:,0], cmap='gray')\n",
        "            axs[i,j].axis('off')\n",
        "            c += 1\n",
        "\n",
        "    if save:\n",
        "        fig.savefig(\"{}_{}.png\".format(name, epoch))\n",
        "        plt.close()\n",
        "    else:\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "qu1yrSr4D1ZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X, _), (_, _) = kr.datasets.mnist.load_data()\n",
        "\n",
        "X = X.reshape(X.shape[0], 28, 28, 1).astype('float32')\n",
        "X = (X - 127.5) / 127.5 # Normalize the images to [-1, 1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wp2-WkQyD63_",
        "outputId": "07a689b3-5947-477c-d01e-fc53f3de9398"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator(output_shape=(28, 28, 1)):\n",
        "    model = kr.Sequential(name='generator')\n",
        "\n",
        "    model.add(kr.layers.Dense(256, input_shape=(LATENT_DIM, )))\n",
        "    model.add(kr.layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(kr.layers.BatchNormalization(momentum=0.8))\n",
        "\n",
        "    model.add(kr.layers.Dense(512))\n",
        "    model.add(kr.layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(kr.layers.BatchNormalization(momentum=0.8))\n",
        "\n",
        "    model.add(kr.layers.Dense(1024))\n",
        "    model.add(kr.layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(kr.layers.BatchNormalization(momentum=0.8))\n",
        "\n",
        "    model.add(kr.layers.Dense(np.prod(output_shape), activation='tanh'))\n",
        "    model.add(kr.layers.Reshape(output_shape))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "generator = build_generator()\n",
        "generator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgCcFfCyEAyw",
        "outputId": "85ced0ee-2636-40f3-fbad-0abb70ed7e0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 256)               25856     \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 256)               0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 256)              1024      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               131584    \n",
            "                                                                 \n",
            " leaky_re_lu_1 (LeakyReLU)   (None, 512)               0         \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1024)              525312    \n",
            "                                                                 \n",
            " leaky_re_lu_2 (LeakyReLU)   (None, 1024)              0         \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 1024)             4096      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 784)               803600    \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 28, 28, 1)         0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,493,520\n",
            "Trainable params: 1,489,936\n",
            "Non-trainable params: 3,584\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator(input_shape=(28, 28, 1)):\n",
        "    model = kr.Sequential(name='discriminator')\n",
        "\n",
        "    model.add(kr.layers.Flatten(input_shape=input_shape))\n",
        "    model.add(kr.layers.Dense(512))\n",
        "    model.add(kr.layers.LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(kr.layers.Dense(256))\n",
        "    model.add(kr.layers.LeakyReLU(alpha=0.2))\n",
        "\n",
        "    model.add(kr.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "discriminator = build_discriminator()\n",
        "discriminator.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oHLy4dwEKF-",
        "outputId": "e0b814b9-e69b-4105-a6d7-789855e3f751"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 512)               401920    \n",
            "                                                                 \n",
            " leaky_re_lu_3 (LeakyReLU)   (None, 512)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " leaky_re_lu_4 (LeakyReLU)   (None, 256)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 533,505\n",
            "Trainable params: 533,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = kr.optimizers.Adam(0.0002, 0.5)\n",
        "\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=optimizer,  metrics=['acc'])\n",
        "discriminator.trainable = False    # For GAN we will only train the generator\n",
        "\n",
        "z = kr.Input(shape=(LATENT_DIM,))\n",
        "valid = discriminator(generator(z))\n",
        "\n",
        "model = kr.Model(z, valid)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thDa702OEPld",
        "outputId": "01e6064e-ec7e-46b2-861c-98d56345861a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 100)]             0         \n",
            "                                                                 \n",
            " generator (Sequential)      (None, 28, 28, 1)         1493520   \n",
            "                                                                 \n",
            " discriminator (Sequential)  (None, 1)                 533505    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,027,025\n",
            "Trainable params: 1,489,936\n",
            "Non-trainable params: 537,089\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7D-lbfULD-OR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SRGAN(\"Super-Resolution Generative Adversarial Network.)"
      ],
      "metadata": {
        "id": "6ywiE8PoE4c6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, math, sys\n",
        "import glob, itertools\n",
        "import argparse, random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torchvision.models import vgg19\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.utils import save_image, make_grid\n",
        "import plotly\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "random.seed(42)\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "AI5auAG1FWPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load pretrained models\n",
        "load_pretrained_models = True\n",
        "# number of epochs of training\n",
        "n_epochs = 3\n",
        "# name of the dataset\n",
        "dataset_path = \"../input/celeba-dataset/img_align_celeba/img_align_celeba\"\n",
        "# size of the batches\n",
        "batch_size = 16\n",
        "# adam: learning rate\n",
        "lr = 0.00008\n",
        "# adam: decay of first order momentum of gradient\n",
        "b1 = 0.5\n",
        "# adam: decay of second order momentum of gradient\n",
        "b2 = 0.999\n",
        "# epoch from which to start lr decay\n",
        "decay_epoch = 100\n",
        "# number of cpu threads to use during batch generation\n",
        "n_cpu = 8\n",
        "# high res. image height\n",
        "hr_height = 256\n",
        "# high res. image width\n",
        "hr_width = 256\n",
        "# number of image channels\n",
        "channels = 3\n",
        "os.makedirs(\"images\", exist_ok=True)\n",
        "os.makedirs(\"saved_models\", exist_ok=True)\n",
        "cuda = torch.cuda.is_available()\n",
        "hr_shape = (hr_height, hr_width)"
      ],
      "metadata": {
        "id": "WW9EYU_zFh_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean = np.array([0.485, 0.456, 0.406])\n",
        "std = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, files, hr_shape):\n",
        "        hr_height, hr_width = hr_shape\n",
        "        # Transforms for low resolution images and high resolution images\n",
        "        self.lr_transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.Resize((hr_height // 4, hr_height // 4), Image.BICUBIC),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean, std),\n",
        "            ]\n",
        "        )\n",
        "        self.hr_transform = transforms.Compose(\n",
        "            [\n",
        "                transforms.Resize((hr_height, hr_height), Image.BICUBIC),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize(mean, std),\n",
        "            ]\n",
        "        )\n",
        "        self.files = files\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = Image.open(self.files[index % len(self.files)])\n",
        "        img_lr = self.lr_transform(img)\n",
        "        img_hr = self.hr_transform(img)\n",
        "\n",
        "        return {\"lr\": img_lr, \"hr\": img_hr}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)"
      ],
      "metadata": {
        "id": "54cR77u4Hl3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#cyclae gan"
      ],
      "metadata": {
        "id": "LoWlMd6AH18E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepspeed"
      ],
      "metadata": {
        "id": "eIsUuvygH4Z1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9da1a01b-eb27-412e-a2e2-9441dbe999cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepspeed\n",
            "  Downloading deepspeed-0.10.0.tar.gz (836 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m836.6/836.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting hjson (from deepspeed)\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja (from deepspeed)\n",
            "  Downloading ninja-1.11.1-py2.py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (145 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.0/146.0 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from deepspeed) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed) (9.0.0)\n",
            "Requirement already satisfied: pydantic<2.0.0 in /usr/local/lib/python3.10/dist-packages (from deepspeed) (1.10.11)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from deepspeed) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deepspeed) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2.0.0->deepspeed) (4.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->deepspeed) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deepspeed) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->deepspeed) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->deepspeed) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->deepspeed) (1.3.0)\n",
            "Building wheels for collected packages: deepspeed\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.10.0-py3-none-any.whl size=877457 sha256=0092220668ed87b769def860dd795614a790f24e220fc82bef38f89323b774e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/7b/3f/2807682bad2fba40ed888e6309597a5fda545ab30964c835aa\n",
            "Successfully built deepspeed\n",
            "Installing collected packages: ninja, hjson, deepspeed\n",
            "Successfully installed deepspeed-0.10.0 hjson-3.1.0 ninja-1.11.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytorch_lightning\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBA320jncTWc",
        "outputId": "1af61d91-344c-47c1-a941-2ebcf5ae76dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch_lightning\n",
            "  Downloading pytorch_lightning-2.0.5-py3-none-any.whl (722 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m722.4/722.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.65.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch_lightning)\n",
            "  Downloading torchmetrics-1.0.1-py3-none-any.whl (729 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m729.2/729.2 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (23.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.7.1)\n",
            "Collecting lightning-utilities>=0.7.0 (from pytorch_lightning)\n",
            "  Downloading lightning_utilities-0.9.0-py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.27.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (3.8.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch_lightning) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch_lightning) (16.0.6)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->pytorch_lightning) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->pytorch_lightning) (1.3.0)\n",
            "Installing collected packages: lightning-utilities, torchmetrics, pytorch_lightning\n",
            "Successfully installed lightning-utilities-0.9.0 pytorch_lightning-2.0.5 torchmetrics-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "import deepspeed as ds\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pytorch_lightning as L\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "from pytorch_lightning.utilities import CombinedLoader\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.io import read_image\n",
        "from torchvision.utils import make_grid, save_image\n",
        "_ = L.seed_everything(0, workers=True)"
      ],
      "metadata": {
        "id": "5kCHkjItH8IY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f84912a-f14a-4802-e049-f99ab29c7953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def show_img(img_tensor, nrow, title=\"\"):\n",
        "    img_tensor = img_tensor.detach().cpu() * 0.5 + 0.5\n",
        "    img_grid = make_grid(img_tensor, nrow=nrow).permute(1, 2, 0)\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    plt.imshow(img_grid)\n",
        "    plt.axis(\"off\")\n",
        "    plt.title(title)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "iC6t214vIJL4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTransform(object):\n",
        "    def __init__(self, load_dim=286, target_dim=256):\n",
        "        self.transform_train = T.Compose([\n",
        "            T.Resize((load_dim, load_dim), antialias=True),\n",
        "            T.RandomCrop((target_dim, target_dim)),\n",
        "            T.RandomHorizontalFlip(p=0.5),\n",
        "            T.ColorJitter(brightness=0.2, contrast=0.2,\n",
        "                          saturation=0.2, hue=0.1),\n",
        "        ])\n",
        "        self.transform = T.Resize((target_dim, target_dim), antialias=True)\n",
        "    def __call__(self, img, stage):\n",
        "        if stage == \"fit\":\n",
        "            img = self.transform_train(img)\n",
        "        else:\n",
        "            img = self.transform(img)\n",
        "        return img * 2 - 1"
      ],
      "metadata": {
        "id": "mPRhY8UDIMNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEBUG = False\n",
        "\n",
        "DM_CONFIG = {\n",
        "    \"monet_dir\": os.path.join(\"/kaggle/input/gan-getting-started/monet_jpg\", \"*.jpg\"),\n",
        "    \"photo_dir\": os.path.join(\"/kaggle/input/gan-getting-started/photo_jpg\", \"*.jpg\"),\n",
        "\n",
        "    \"loader_config\": {\n",
        "        \"num_workers\": os.cpu_count(),\n",
        "        \"pin_memory\": torch.cuda.is_available(),\n",
        "    },\n",
        "    \"sample_size\": 5,\n",
        "    \"batch_size\": 1 if not DEBUG else 1,\n",
        "}"
      ],
      "metadata": {
        "id": "oPI6ZnvSIPL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDataModule(L.LightningDataModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        monet_dir,\n",
        "        photo_dir,\n",
        "        loader_config,\n",
        "        sample_size,\n",
        "        batch_size,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.loader_config = loader_config\n",
        "        self.sample_size = sample_size\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        # store file paths\n",
        "        self.monet_filenames = sorted(glob.glob(monet_dir))\n",
        "        self.photo_filenames = sorted(glob.glob(photo_dir))\n",
        "\n",
        "        # define transformations for image augmentation\n",
        "        self.transform = CustomTransform()\n",
        "\n",
        "    def setup(self, stage):\n",
        "        if stage == \"fit\":\n",
        "            self.train_monet = CustomDataset(self.monet_filenames, self.transform, stage)\n",
        "            self.train_photo = CustomDataset(self.photo_filenames, self.transform, stage)\n",
        "\n",
        "        if stage in [\"fit\", \"test\", \"predict\"]:\n",
        "            # to be used for test and prediction datasets as well\n",
        "            self.valid_photo = CustomDataset(self.photo_filenames, self.transform, None)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        loader_config = {\n",
        "            \"shuffle\": True,\n",
        "            \"drop_last\": True,\n",
        "            \"batch_size\": self.batch_size,\n",
        "            **self.loader_config,\n",
        "        }\n",
        "        loader_monet = DataLoader(self.train_monet, **loader_config)\n",
        "        loader_photo = DataLoader(self.train_photo, **loader_config)\n",
        "        loaders = {\"monet\": loader_monet, \"photo\": loader_photo}\n",
        "        return CombinedLoader(loaders, mode=\"max_size_cycle\")\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.valid_photo,\n",
        "            batch_size=self.sample_size,\n",
        "            **self.loader_config,\n",
        "        )\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return self.val_dataloader()\n",
        "\n",
        "    def predict_dataloader(self):\n",
        "        return DataLoader(\n",
        "            self.valid_photo,\n",
        "            batch_size=self.batch_size,\n",
        "            **self.loader_config,\n",
        "        )"
      ],
      "metadata": {
        "id": "mgijIzP0IXVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dm_sample = CustomDataModule(batch_size=5, **{k: v for k, v in DM_CONFIG.items() if k != \"batch_size\"})\n",
        "dm_sample.setup(\"fit\")\n",
        "train_loader = dm_sample.train_dataloader()\n",
        "imgs = next(iter(train_loader))\n",
        "show_img(imgs[\"monet\"], nrow=5, title=\"Augmented Monet Paintings\")\n",
        "show_img(imgs[\"photo\"], nrow=5, title=\"Augmented Photos\")"
      ],
      "metadata": {
        "id": "wzVd9_7WIclD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "97d84df3-f9e4-495e-a450-6fe00111b7ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-0ce2aafb0624>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdm_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomDataModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mDM_CONFIG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"batch_size\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdm_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fit\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdm_sample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mshow_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"monet\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Augmented Monet Paintings\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-b4820c8c8b7e>\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"fit\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_monet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonet_filenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_photo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphoto_filenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'CustomDataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s_cIsoZ3IgFg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}